{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import steamspypi\n",
    "import steamreviews\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the 100 most popular games on steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_request = {\"request\": \"top100owned\"}\n",
    "data = steamspypi.download(data_request)\n",
    "df = pd.DataFrame(data.values())\n",
    "df = df[['name', 'appid']]\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(appid):\n",
    "    data_request = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    data = steamspypi.download(data_request)\n",
    "    return data['tags']\n",
    "\n",
    "df['tags'] = df['appid'].apply(get_tags)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct player networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it make sense to prune the friends of seed players based on wether they have the original game or not? The two options are smartly choosing the seed players or recursively looking at friends of friends who have the game until we have a big enough network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friends_with_game(player_id, app_id):\n",
    "    \"\"\" \n",
    "    Given a player_id and an app_id, returns a list of the player's friends who own the game.\n",
    "    \"\"\"\n",
    "    all_friends = []\n",
    "    url = f'http://api.steampowered.com/ISteamUser/GetFriendList/v0001/?key={API_KEY}&steamid={player_id}&relationship=friend'\n",
    "    response = requests.get(url)\n",
    "    friend_list = response.json()\n",
    "    try:\n",
    "        for item in friend_list[\"friendslist\"][\"friends\"]:\n",
    "            all_friends.append(item[\"steamid\"])\n",
    "    except:\n",
    "        pass\n",
    "        # print(\"Error getting friends.\")\n",
    "    friends_with_game = []\n",
    "    for friend in all_friends:\n",
    "        games = []\n",
    "        url = f'http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key={API_KEY}&steamid={friend}&format=json'\n",
    "        response = requests.get(url)\n",
    "        game_list = response.json()\n",
    "        try:\n",
    "            for item in game_list[\"response\"][\"games\"]:\n",
    "                games.append(item[\"appid\"])\n",
    "        except:\n",
    "            continue\n",
    "        if app_id in games:\n",
    "            friends_with_game.append(friend)\n",
    "    return friends_with_game\n",
    "    \n",
    "def get_friends(player_id):\n",
    "    \"\"\" \n",
    "    Given a player_id, returns a list of the player's friends.\n",
    "    \"\"\"\n",
    "    all_friends = []\n",
    "    url = f'http://api.steampowered.com/ISteamUser/GetFriendList/v0001/?key={API_KEY}&steamid={player_id}&relationship=friend'\n",
    "    response = requests.get(url)\n",
    "    friend_list = response.json()\n",
    "    try:\n",
    "        for item in friend_list[\"friendslist\"][\"friends\"]:\n",
    "            all_friends.append(item[\"steamid\"])\n",
    "    except:\n",
    "        pass\n",
    "        # print(\"Error getting friends.\")\n",
    "    return all_friends    \n",
    "    \n",
    "def get_ownership_network(app_id, params, seed_size=10, min_net_size=100):\n",
    "    \"\"\" \n",
    "    Given an app_id, returns a list of players who own the game and their friends who own the game.\n",
    "    \"\"\"\n",
    "    # Get seed players\n",
    "    review_dict, query_count = steamreviews.download_reviews_for_app_id(app_id, chosen_request_params=params)\n",
    "    players = []\n",
    "    for key in review_dict[\"reviews\"].keys():\n",
    "        if len(players) < seed_size:\n",
    "            players.append(review_dict[\"reviews\"][key][\"author\"][\"steamid\"])\n",
    "    network = players.copy()\n",
    "    queue = players.copy()\n",
    "    while queue:\n",
    "        player = queue.pop(0)\n",
    "        friends = get_friends_with_game(player, app_id)\n",
    "        for friend in friends:\n",
    "            if friend not in network:\n",
    "                network.append(friend)\n",
    "                queue.append(friend)\n",
    "                # print(f\"Added {friend} to the network.\")\n",
    "                if len(network) >= min_net_size:\n",
    "                    return network\n",
    "    return network\n",
    "\n",
    "def get_non_ownership_network(app_id, params, seed_size=10, min_net_size=100):\n",
    "    \"\"\" \n",
    "    Given an app_id, returns a friendship network of seed players. Friends of seeded players don't necessarily own the game.\n",
    "    \"\"\"\n",
    "    # Get seed players\n",
    "    review_dict, query_count = steamreviews.download_reviews_for_app_id(app_id, chosen_request_params=params)\n",
    "    players = []\n",
    "    for key in review_dict[\"reviews\"].keys():\n",
    "        if len(players) < seed_size:\n",
    "            players.append(review_dict[\"reviews\"][key][\"author\"][\"steamid\"])\n",
    "    print(\"Seed players collected.\")      \n",
    "    network = players.copy()\n",
    "    queue = players.copy()\n",
    "    while queue:\n",
    "        player = queue.pop(0)\n",
    "        friends = get_friends(player)\n",
    "        for friend in friends:\n",
    "            if friend not in network:\n",
    "                network.append(friend)\n",
    "                queue.append(friend)\n",
    "                # print(f\"Added {friend} to the network.\")\n",
    "                if len(network) >= min_net_size:\n",
    "                    return network\n",
    "    return network\n",
    "        \n",
    "        \n",
    "def get_edges(net_nodes):\n",
    "    edges = []\n",
    "    for node in net_nodes:\n",
    "        friends = get_friends(node)\n",
    "        for friend in friends:\n",
    "            if friend in net_nodes:\n",
    "                edges.append((node, friend))\n",
    "    return edges\n",
    "\n",
    "def construct_pajek_network(net_nodes, net_edges, app_id):\n",
    "    with open(f\"./Networks/{app_id}.net\", \"w\") as f:\n",
    "        f.write(\"*Vertices \" + str(len(net_nodes)) + \"\\n\")\n",
    "        for i, node in enumerate(net_nodes):\n",
    "            f.write(str(i+1) + ' \"' + node + '\"\\n')\n",
    "        f.write(\"*Edges\\n\")\n",
    "        for edge in net_edges:\n",
    "            f.write(str(net_nodes.index(edge[0]) + 1) + \" \" + str(net_nodes.index(edge[1]) + 1) + \"\\n\")\n",
    "    \n",
    "def construct_network(app_id, params, seed_size=10, min_net_size=100):\n",
    "    net_nodes = get_non_ownership_network(app_id, params, seed_size, min_net_size)\n",
    "    print(\"Nodes collected.\")\n",
    "    net_edges = get_edges(net_nodes)\n",
    "    print(\"Edges collected.\")\n",
    "    construct_pajek_network(net_nodes, net_edges, app_id)\n",
    "    print(\"Network constructed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_params = dict()\n",
    "request_params['language'] = 'english'\n",
    "request_params['review_type'] = 'positive'\n",
    "request_params['purchase_type'] = 'steam'\n",
    "request_params['day_range'] = '30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./Networks\")\n",
    "files = [file.split(\".\")[0] for file in files]\n",
    "for row in df.iterrows():\n",
    "    app_id = row[1]['appid']\n",
    "    if str(app_id) not in files:\n",
    "        print(f\"Constructing network for {row[1]['name']}.\")\n",
    "        construct_network(app_id, request_params, 10, 10000)\n",
    "    else:\n",
    "        print(f\"Network for {row[1]['name']} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the overall structure of the friendship networks, including metrics like density, average degree, and assortativity. Are there significant differences in how connected or clustered the networks are based on the games?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "files = os.listdir(\"./Networks\")\n",
    "for file in files:\n",
    "    id = file.split(\".\")[0]\n",
    "    G = nx.read_pajek(f\"./Networks/{file}\")\n",
    "    G = nx.Graph(G)\n",
    "    if G.number_of_nodes() == 0:\n",
    "        continue\n",
    "    clustering_coefficient = nx.average_clustering(G)\n",
    "    avg_degree = sum(dict(G.degree()).values()) / len(G)\n",
    "    density = nx.density(G)\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    df.loc[df['appid'] == int(id), 'avg_degree'] = avg_degree\n",
    "    df.loc[df['appid'] == int(id), 'density'] = density\n",
    "    df.loc[df['appid'] == int(id), 'clustering_coefficient'] = clustering_coefficient\n",
    "    df.loc[df['appid'] == int(app_id), 'largest_connected_component'] = len(largest_cc)\n",
    "    \n",
    "df.to_csv(\"steam_data.csv\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(df['avg_degree'], df['density'], df['clustering_coefficient'])\n",
    "ax.set_xlabel('Average Degree')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_zlabel('Clustering Coefficient')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Investigate the centrality of nodes (players) within each network. Are there players who act as hubs or connectors within their respective communities? Do certain games tend to have more centralized or decentralized networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./Networks\")\n",
    "df = pd.read_csv(\"steam_data.csv\")\n",
    "for file in files:\n",
    "    id = file.split(\".\")[0]\n",
    "    G = nx.read_pajek(f\"./Networks/{file}\")\n",
    "    G = nx.Graph(G)\n",
    "    if G.number_of_nodes() == 0:\n",
    "        continue\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    df.loc[df['appid'] == int(id), 'degree_centrality'] = np.mean(list(degree_centrality.values()))\n",
    "    df.loc[df['appid'] == int(id), 'closeness_centrality'] = np.mean(list(closeness_centrality.values()))\n",
    "    df.loc[df['appid'] == int(id), 'betweenness_centrality'] = np.mean(list(betweenness_centrality.values()))\n",
    "df.to_csv(\"steam_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1)\n",
    "axs[0].hist(df['degree_centrality'], bins=72)\n",
    "axs[0].set_title('Degree Centrality')\n",
    "axs[1].hist(df['closeness_centrality'], bins=72)\n",
    "axs[1].set_title('Closeness Centrality')\n",
    "axs[2].hist(df['betweenness_centrality'], bins=72)\n",
    "axs[2].set_title('Betweenness Centrality')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply community detection algorithms to identify groups or communities within each network. Are there distinct community structures associated with different games? How do these communities overlap or interact?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_dir = 'Networks_100_1000'\n",
    "#network_dir = os.path.join(extraction_dir, 'Networks_100_1000')\n",
    "network_files = os.listdir(extraction_dir)\n",
    "network_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_files_string = \"','\".join(network_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_files_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def visualize_network(file_path, title):\n",
    "    G = nx.read_pajek(file_path)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    nx.draw_spring(G, node_size=20, with_labels=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "sample_files = ['413150.net', '578080.net', '271590.net', '1174180.net', '730.net']\n",
    "for file_name in sample_files:\n",
    "    file_path = os.path.join(extraction_dir, file_name)\n",
    "    visualize_network(file_path, f'Network: {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_network(file_path):\n",
    "    return nx.read_pajek(file_path)\n",
    "def convert_to_simple_graph(G):\n",
    "    H = nx.Graph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if H.has_edge(u, v):\n",
    "            if 'weight' in data:\n",
    "                H[u][v]['weight'] += data['weight']\n",
    "            else:\n",
    "                H[u][v]['weight'] += 1  \n",
    "        else:\n",
    "            if 'weight' in data:\n",
    "                H.add_edge(u, v, **data)\n",
    "            else:\n",
    "                H.add_edge(u, v, weight=1)  \n",
    "    return H\n",
    "def check_connectivity(G):\n",
    "    if len(G) == 0:\n",
    "        return False\n",
    "    return nx.is_connected(G)\n",
    "def analyze_clustering(G):\n",
    "    if len(G) == 0:\n",
    "        return 0\n",
    "    clustering_coefficients = nx.clustering(G)\n",
    "    avg_clustering = sum(clustering_coefficients.values()) / len(clustering_coefficients)\n",
    "    return avg_clustering\n",
    "def degree_distribution(G):\n",
    "    degrees = [degree for node, degree in G.degree()]\n",
    "    return degrees\n",
    "def visualize_network(G, title):\n",
    "    if len(G) == 0:\n",
    "        print(f\"Cannot visualize network {title} because it is empty.\")\n",
    "        return\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    nx.draw_spring(G, node_size=20, with_labels=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "network_files = ['413150.net','438100.net','304930.net','578080.net','755790.net','550650.net','532210.net','10.net','8930.net','1097150.net','945360.net','1938090.net','291480.net','1623730.net','1174180.net','477160.net','301520.net','417910.net','291550.net','570.net','252490.net','582010.net','1811260.net','230410.net','553850.net','4000.net','377160.net','1086940.net','251570.net','105600.net','386360.net','250900.net','239140.net','431960.net','70.net','1245620.net','444090.net','400.net','49520.net','901583.net','814380.net']\n",
    "results = []\n",
    "for file_name in network_files:\n",
    "    file_path = os.path.join(extraction_dir, file_name)\n",
    "    G = load_network(file_path)\n",
    "    G_simple = convert_to_simple_graph(G)\n",
    "    connectivity = check_connectivity(G_simple)\n",
    "    results.append((file_name, 'Connected', connectivity))\n",
    "    avg_clustering = analyze_clustering(G_simple)\n",
    "    results.append((file_name, 'Average Clustering Coefficient', avg_clustering))\n",
    "    degrees = degree_distribution(G_simple)\n",
    "    plt.figure()\n",
    "    plt.hist(degrees, bins=30)\n",
    "    plt.title(f\"Degree Distribution: {file_name}\")\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    visualize_network(G_simple, f'Network: {file_name}')\n",
    "results_df = pd.DataFrame(results, columns=['Network', 'Metric', 'Value'])\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_dir = 'Networks_100_1000'\n",
    "network_files = ['413150.net','438100.net','304930.net','578080.net','755790.net','550650.net','532210.net','10.net','8930.net','1097150.net','945360.net','1938090.net','291480.net','1623730.net','1174180.net','477160.net','301520.net','417910.net','291550.net','570.net','252490.net','582010.net','1811260.net','230410.net','553850.net','4000.net','377160.net','1086940.net','251570.net','105600.net','386360.net','250900.net','239140.net','431960.net','70.net','1245620.net','444090.net','400.net','49520.net','901583.net','814380.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "hub_results = []\n",
    "def identify_hubs(G, threshold=2):\n",
    "    \"\"\"\n",
    "    Identify hubs in the graph. Hubs are nodes with a degree greater than\n",
    "    a certain threshold times the average degree of the network.\n",
    "    \"\"\"\n",
    "    if len(G) == 0:\n",
    "        return []\n",
    "    \n",
    "    avg_degree = sum(dict(G.degree()).values()) / len(G)\n",
    "    hubs = [node for node, degree in G.degree() if degree > threshold * avg_degree]\n",
    "    return hubs\n",
    "def visualize_hub_distribution(G, hubs, title):\n",
    "    \"\"\"\n",
    "    Visualize the degree distribution of hubs in the network.\n",
    "    \"\"\"\n",
    "    if not hubs:\n",
    "        print(f\"No hubs identified in network {title}.\")\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.hist([G.degree(node) for node in hubs], bins=30)\n",
    "    plt.title(f\"Hub Degree Distribution: {title}\")\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "for file_name in network_files:\n",
    "    file_path = os.path.join(extraction_dir, file_name)\n",
    "    G = load_network(file_path)\n",
    "    G_simple = convert_to_simple_graph(G)\n",
    "    hubs = identify_hubs(G_simple)\n",
    "    hub_results.append((file_name, 'Number of Hubs', len(hubs)))\n",
    "    visualize_hub_distribution(G_simple, hubs, file_name)\n",
    "hub_results_df = pd.DataFrame(hub_results, columns=['Network', 'Metric', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Verification  if our networks are scale free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "def load_network(file_path):\n",
    "    return nx.read_pajek(file_path)\n",
    "\n",
    "\n",
    "def convert_to_simple_graph(G):\n",
    "    H = nx.Graph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if H.has_edge(u, v):\n",
    "            if 'weight' in data:\n",
    "                H[u][v]['weight'] += data['weight']\n",
    "            else:\n",
    "                H[u][v]['weight'] += 1  \n",
    "        else:\n",
    "            if 'weight' in data:\n",
    "                H.add_edge(u, v, **data)\n",
    "            else:\n",
    "                H.add_edge(u, v, weight=1)  \n",
    "    return H\n",
    "def degree_distribution(G):\n",
    "    degrees = [degree for node, degree in G.degree()]\n",
    "    return degrees\n",
    "def check_scale_free(G):\n",
    "    degrees = degree_distribution(G)\n",
    "    fit = powerlaw.Fit(degrees)\n",
    "    alpha = fit.power_law.alpha\n",
    "    xmin = fit.power_law.xmin\n",
    "    R, p = fit.distribution_compare('power_law', 'exponential')\n",
    "    return alpha, xmin, R, p\n",
    "extraction_dir = 'Networks_100_1000'\n",
    "network_files = [\n",
    "    '413150.net','438100.net','304930.net','578080.net','755790.net','550650.net',\n",
    "    '532210.net','10.net','8930.net','1097150.net','945360.net','1938090.net',\n",
    "    '291480.net','1623730.net','1174180.net','477160.net','301520.net','417910.net',\n",
    "    '291550.net','570.net','252490.net','582010.net','1811260.net','230410.net',\n",
    "    '553850.net','4000.net','377160.net','1086940.net','251570.net','105600.net',\n",
    "    '386360.net','250900.net','239140.net','431960.net','70.net','1245620.net',\n",
    "    '444090.net','400.net','49520.net','901583.net','814380.net'\n",
    "]\n",
    "\n",
    "scale_free_results = []\n",
    "\n",
    "for file_name in network_files:\n",
    "    file_path = os.path.join(extraction_dir, file_name)\n",
    "    G = load_network(file_path)\n",
    "    G_simple = convert_to_simple_graph(G)\n",
    "    # Check if the network is scale-free\n",
    "    alpha, xmin, R, p = check_scale_free(G_simple)\n",
    "    scale_free_results.append((file_name, 'Alpha', alpha))\n",
    "    scale_free_results.append((file_name, 'Xmin', xmin))\n",
    "    scale_free_results.append((file_name, 'R', R))\n",
    "    scale_free_results.append((file_name, 'P-Value', p))\n",
    "scale_free_results_df = pd.DataFrame(scale_free_results, columns=['Network', 'Metric', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_free_results_df = pd.DataFrame(scale_free_results, columns=['Network', 'Metric', 'Value'])\n",
    "scale_free_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisfaction to the distribution follow a power law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follows_power_law(df):\n",
    "    power_law_networks = df[df['Metric'] == 'P-Value']\n",
    "    power_law_networks['Follows_Power_Law'] = power_law_networks['Value'] < 0.05\n",
    "    return power_law_networks\n",
    "power_law_networks = follows_power_law(scale_free_results_df)\n",
    "print(power_law_networks)\n",
    "power_law_networks.to_csv('scale_free_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lcc(G):\n",
    "    if len(G) == 0:\n",
    "        return nx.Graph()  \n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc).copy()\n",
    "def expand_lcc(G, lcc):\n",
    "    if len(lcc) == 0:\n",
    "        return nx.Graph() \n",
    "    nodes_to_expand = set(lcc.nodes())\n",
    "    for node in list(lcc.nodes()):\n",
    "        neighbors = set(G.neighbors(node))\n",
    "        nodes_to_expand.update(neighbors)\n",
    "    expanded_subgraph = G.subgraph(nodes_to_expand).copy()\n",
    "    return expanded_subgraph\n",
    "def save_network(G, file_path):\n",
    "    nx.write_pajek(G, file_path)\n",
    "extraction_dir = 'Networks_100_1000'\n",
    "expanded_network_dir = 'Expanded_Networks'\n",
    "os.makedirs(expanded_network_dir, exist_ok=True)\n",
    "network_files = [\n",
    "    '413150.net','438100.net','304930.net','578080.net','755790.net','550650.net',\n",
    "    '532210.net','10.net','8930.net','1097150.net','945360.net','1938090.net',\n",
    "    '291480.net','1623730.net','1174180.net','477160.net','301520.net','417910.net',\n",
    "    '291550.net','570.net','252490.net','582010.net','1811260.net','230410.net',\n",
    "    '553850.net','4000.net','377160.net','1086940.net','251570.net','105600.net',\n",
    "    '386360.net','250900.net','239140.net','431960.net','70.net','1245620.net',\n",
    "    '444090.net','400.net','49520.net','901583.net','814380.net'\n",
    "]\n",
    "for file_name in network_files:\n",
    "    file_path = os.path.join(extraction_dir, file_name)\n",
    "    G = load_network(file_path)\n",
    "    G_simple = convert_to_simple_graph(G)\n",
    "    if len(G_simple) == 0:\n",
    "        print(f\"Skipping {file_name} as it is empty after conversion.\")\n",
    "        continue\n",
    "    G_lcc = get_lcc(G_simple)\n",
    "    G_expanded = expand_lcc(G_simple, G_lcc)\n",
    "    if len(G_expanded) == 0:\n",
    "        print(f\"Skipping {file_name} as it has no valid largest connected component.\")\n",
    "        continue\n",
    "    expanded_file_path = os.path.join(expanded_network_dir, file_name)\n",
    "    save_network(G_expanded, expanded_file_path)\n",
    "print(f\"Expanded networks have been saved to the '{expanded_network_dir}' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
